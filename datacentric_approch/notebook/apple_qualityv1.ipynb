{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 \n",
    "-IMPORT ALL REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder,OneHotEncoder\n",
    "from sklearn import feature_selection\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 \n",
    "-READ FILES USING PANDAS PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir,\"Datasets\",\"apple_quality.csv\")\n",
    "data = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3\n",
    "-EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see that data typr mentioned here for **Acidity** is Object but its actually float so we need to conver it into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"Acidity\"] = (data[\"Acidity\"]).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()\n",
    "# now if you obseve at end there is string at end of the row \n",
    "# so remove it and rerun the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = data.drop(data.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Acidity\"] = (data[\"Acidity\"]).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Set **A_id** as index or remove it as it's not a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"A_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using\n",
    "- describe()\n",
    "- info()<br>\n",
    "\n",
    "to get information regarding each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can observe from above that there are no missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = template.data_val(data)\n",
    "column_types = data_val.get_column_type()\n",
    "data_val.zero_count(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also there are no zeros in the data cause sometimes erp or iot systems or legacy systems assigned zeros to the data sample where its null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_count = data_val.zero_count1()\n",
    "print(zeros_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = data_val.schema()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in pd.unique(data[\"Quality\"]):\n",
    "    print(f\"{cat} =\",(data[\"Quality\"]==cat).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_scaled = data_val.scale_dataset(Oversample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(data=data_scaled)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_val.remove_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data_cleaned)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = data_val.scale_dataset()\n",
    "sns.boxplot(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=(data_scaled),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_val.histplot_columns(2,4,figuresize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,col_types in column_types.items():\n",
    "    if col_types == \"categorical\":\n",
    "        x= data[col].values.reshape(-1,1)\n",
    "        encoder.fit(x)\n",
    "        data[col]=encoder.transform(x).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,col_types in column_types.items():\n",
    "    if col_types == \"categorical\":\n",
    "        x= data_scaled[col].values.reshape(-1,1)\n",
    "        encoder.fit(x)\n",
    "        data_scaled[col]=encoder.transform(x).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_scaled,hue=\"Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap = data_scaled.corr()\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(11,9))\n",
    "mask = np.triu(np.ones_like(corrmap, dtype=bool))\n",
    "cmap = sns.diverging_palette(15,260, as_cmap=True)\n",
    "sns.heatmap(corrmap,cmap=cmap,mask=mask,annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_scaled[data_scaled.columns[:-1]]\n",
    "y = data_scaled[data_scaled.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1.head()\n",
    "print(x_train1.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x_train1.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_new = feature_selection.SelectKBest(feature_selection.f_classif,k=5).fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature = x_new.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train1[selected_feature]\n",
    "x_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([x_train2, y_train1],axis=1)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data1,hue=\"Quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "clf = LogisticRegression()\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=clf,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=2,\n",
    ")\n",
    "rfecv.fit(x_train1, y_train1)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming rfecv is your RFECV object\n",
    "cv_results = pd.DataFrame(rfecv.cv_results_)\n",
    "\n",
    "# Adding the n_features column\n",
    "cv_results['n_features'] = range(1, len(cv_results) + 1)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.errorbar(\n",
    "    x=cv_results[\"n_features\"],\n",
    "    y=cv_results[\"mean_test_score\"],\n",
    "    yerr=cv_results[\"std_test_score\"],\n",
    "    fmt='-o'  # Add this for better visualization (line with circle markers)\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming rfecv is your RFECV object\n",
    "cv_results = pd.DataFrame(rfecv.cv_results_)\n",
    "print(cv_results.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import  BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,classification_report,confusion_matrix,accuracy_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1 = x_test1[selected_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given Dataset is of small size and does not occupy large memory based on that aplicable algorithms for classification are : \n",
    "1. Logistic Regression\n",
    "2. K-nn classification\n",
    "3. SVM classification\n",
    "4. Decision tree\n",
    "5. RandomForest\n",
    "6. Gradient Boosting Machines\n",
    "6. Adaboost\n",
    "7. XGboost\n",
    "8. LightGbm\n",
    "9. CatBoost\n",
    "10. Naive Bayes\n",
    "11. SGD\n",
    "12. Ridge Classifier\n",
    "13. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic_regression\" : LogisticRegression(),\n",
    "    \"SVC_kernel\" : SVC(kernel=\"rbf\",gamma=\"scale\"),\n",
    "    \"SVC_kernel_poly\" : SVC(kernel=\"poly\",gamma=\"scale\",degree=3,coef0=1),\n",
    "    \"SVC_kernel_sigmoid\" : SVC(kernel=\"sigmoid\",gamma=\"scale\",coef0= 1),\n",
    "    \"KNN_classification\" : KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "    \"RidgeClassifier\": RidgeClassifier(),\n",
    "    \"BaggingClassifier\": BaggingClassifier()\n",
    "}\n",
    "Accuracy = {}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(x_train2,y_train1)\n",
    "\n",
    "    y_train_pred = model.predict(x_train2)\n",
    "    y_test_pred = model.predict(x_test1)\n",
    "\n",
    "    print(f\"\\033[1m{i+1}. {list(models.keys())[i]}\\033[0m\")\n",
    "    print(f\"Training Accuracy : {model.score(x_train2,y_train1)}\")\n",
    "    print(f\"Testing Accuracy : {model.score(x_test1,y_test1)}\")\n",
    "    print(f\"Training Confusion Matrix : \\n{confusion_matrix(y_train1,y_train_pred)}\")\n",
    "    print(f\"Testing Confusion Matrix : \\n{confusion_matrix(y_test1,y_test_pred)}\")\n",
    "    print(f\"Training Classification Report :\\n {classification_report(y_train1,y_train_pred)}\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"Testing Classification Report : \\n{classification_report(y_test1,y_test_pred)}\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(f\"Precision Report : {accuracy_score(y_train1,y_train_pred)}\")\n",
    "    print(\"================================================================\")\n",
    "\n",
    "    Accuracy[list(models.keys())[i]] = accuracy_score(y_test1,y_test_pred)\n",
    "\n",
    "for i in Accuracy:\n",
    "    print(f\"{i} : {Accuracy[i]}\")   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "def select_models(X, y, interpretability='moderate'):\n",
    "    # Determine if the problem is classification or regression\n",
    "    if y.nunique() <= 10:\n",
    "        problem_type = 'classification'\n",
    "    else:\n",
    "        problem_type = 'regression'\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    models = []\n",
    "    if problem_type == 'classification':\n",
    "        models = [\n",
    "            ('Logistic Regression', LogisticRegression(max_iter=1000)),\n",
    "            ('Decision Tree', DecisionTreeClassifier()),\n",
    "            ('Random Forest', RandomForestClassifier()),\n",
    "            ('Gradient Boosting', GradientBoostingClassifier()),\n",
    "            ('SVM', SVC()),\n",
    "            ('KNN', KNeighborsClassifier()),\n",
    "            ('Naive Bayes', GaussianNB())\n",
    "        ]\n",
    "    else:\n",
    "        models = [\n",
    "            ('Linear Regression', LinearRegression()),\n",
    "            ('Ridge Regression', Ridge()),\n",
    "            ('Lasso Regression', Lasso()),\n",
    "            ('Elastic Net Regression', ElasticNet()),\n",
    "            ('Decision Tree Regressor', DecisionTreeRegressor()),\n",
    "            ('Random Forest Regressor', RandomForestRegressor()),\n",
    "            ('Gradient Boosting Regressor', GradientBoostingRegressor()),\n",
    "            ('SVR', SVR()),\n",
    "            ('KNN Regressor', KNeighborsRegressor())\n",
    "        ]\n",
    "    \n",
    "    selected_models = []\n",
    "\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        if problem_type == 'classification':\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f'{name} Accuracy: {accuracy}')\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f'{name} Mean Squared Error: {mse}')\n",
    "\n",
    "        # Select models based on interpretability\n",
    "        if interpretability == 'high' and name in ['Logistic Regression', 'Linear Regression', 'Decision Tree']:\n",
    "            selected_models.append(model)\n",
    "        elif interpretability == 'moderate' and name in ['Random Forest', 'Gradient Boosting', 'Ridge Regression', 'Lasso Regression', 'Elastic Net Regression']:\n",
    "            selected_models.append(model)\n",
    "        elif interpretability == 'low' and name in ['Neural Networks', 'SVM', 'SVR']:\n",
    "            selected_models.append(model)\n",
    "    \n",
    "    return selected_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "def select_model(X, y, interpretability='moderate'):\n",
    "    # Determine problem type\n",
    "    problem_type = 'classification' if len(y.unique()) <= 10 else 'regression'\n",
    "    \n",
    "    # Determine dataset size\n",
    "    dataset_size = len(X)\n",
    "    \n",
    "    # Determine dataset dimensionality\n",
    "    dataset_dimensionality = X.shape[1]\n",
    "    \n",
    "    # Select appropriate models based on dataset size and dimensionality\n",
    "    if dataset_size <= 1000:\n",
    "        if dataset_dimensionality <= 50:\n",
    "            if interpretability == 'high':\n",
    "                return LogisticRegression(), LinearRegression(), DecisionTreeClassifier()\n",
    "            elif interpretability == 'moderate':\n",
    "                return RandomForestClassifier(), GradientBoostingClassifier(), Ridge(), Lasso()\n",
    "            elif interpretability == 'low':\n",
    "                return SVC(), KNeighborsClassifier()\n",
    "        else:\n",
    "            if interpretability == 'high':\n",
    "                return LogisticRegression(), LinearRegression(), DecisionTreeClassifier()\n",
    "            elif interpretability == 'moderate':\n",
    "                return RandomForestClassifier(), GradientBoostingClassifier(), Ridge(), Lasso()\n",
    "            elif interpretability == 'low':\n",
    "                return SVC(), KNeighborsClassifier()\n",
    "    else:\n",
    "        if interpretability == 'high':\n",
    "            return DecisionTreeClassifier()\n",
    "        elif interpretability == 'moderate':\n",
    "            return RandomForestClassifier(), GradientBoostingClassifier()\n",
    "        elif interpretability == 'low':\n",
    "            return SVC()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_models(x_train2,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model(x_train2,y_train1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
